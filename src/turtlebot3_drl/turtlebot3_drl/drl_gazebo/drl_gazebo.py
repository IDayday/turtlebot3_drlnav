#!/usr/bin/env python3
#
# Copyright 2019 ROBOTIS CO., LTD.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Authors: Ryan Shim, Gilbert, Tomas

import os
import random
import math
import numpy as np
import torch
import time
import sys

from gazebo_msgs.srv import DeleteEntity, SpawnEntity
from std_srvs.srv import Empty
from geometry_msgs.msg import Pose

import rclpy
from rclpy.qos import QoSProfile
from rclpy.node import Node

from turtlebot3_msgs.srv import RingGoal
import xml.etree.ElementTree as ET
from ..drl_environment.drl_environment import ARENA_LENGTH, ARENA_WIDTH, ENABLE_DYNAMIC_GOALS
from ..common.settings import ENABLE_TRUE_RANDOM_GOALS, SEED

NO_GOAL_SPAWN_MARGIN = 0.3 # meters away from any wall
class DRLGazebo(Node):
    def __init__(self, train):
        super().__init__('drl_gazebo')

        """************************************************************
        ** Initialise variables
        ************************************************************"""
        # TODO: 路径修改？
        self.entity_dir_path = (os.path.dirname(os.path.realpath(__file__))).replace(
            'turtlebot3_drl/lib/python3.8/site-packages/turtlebot3_drl/drl_gazebo',
            'turtlebot3_gazebo/share/turtlebot3_gazebo/models/turtlebot3_drl_world/goal_box')
        self.entity_path = os.path.join(self.entity_dir_path, 'model.sdf')
        self.entity = open(self.entity_path, 'r').read()
        self.entity_name = 'goal'
        self.train = train

        with open(os.getenv('DRLNAV_BASE_PATH') + '/tmp/drlnav_current_stage.txt', 'r') as f:
            self.stage = int(f.read())
        print(f"running on stage: {self.stage}, dynamic goals enabled: {ENABLE_DYNAMIC_GOALS}")

        self.prev_x, self.prev_y = -1, -1
        self.goal_x, self.goal_y = 2.0, 0.0
        self.reset_env_times = 0
        self.warm_times = 300
        self.learning_times = 200

        """************************************************************
        ** Initialise ROS publishers, subscribers and clients
        ************************************************************"""
        # Initialise publishers
        self.goal_pose_pub = self.create_publisher(Pose, 'goal_pose', QoSProfile(depth=10))

        # Initialise client
        self.delete_entity_client       = self.create_client(DeleteEntity, 'delete_entity')
        self.spawn_entity_client        = self.create_client(SpawnEntity, 'spawn_entity')
        self.reset_simulation_client    = self.create_client(Empty, 'reset_simulation')
        self.gazebo_pause               = self.create_client(Empty, '/pause_physics')

        # Initialise servers
        self.task_succeed_server    = self.create_service(RingGoal, 'task_succeed', self.task_succeed_callback)
        self.task_fail_server       = self.create_service(RingGoal, 'task_fail', self.task_fail_callback)

        self.obstacle_coordinates   = self.get_obstacle_coordinates()
        self.init_callback()

    """*******************************************************************************
    ** Callback functions and relevant functions
    *******************************************************************************"""

    def init_callback(self):
        self.delete_entity()
        self.reset_simulation()
        self.publish_callback()
        print("Init, goal pose:", self.goal_x, self.goal_y)
        time.sleep(1)

    def publish_callback(self):
        # Publish goal pose
        goal_pose = Pose()
        goal_pose.position.x = self.goal_x
        goal_pose.position.y = self.goal_y
        self.goal_pose_pub.publish(goal_pose)
        self.spawn_entity()

    def task_succeed_callback(self, request, response):
        self.delete_entity()
        if ENABLE_TRUE_RANDOM_GOALS:
            self.generate_random_goal()
            print(f"success: generate (random) a new goal, goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}")
        elif ENABLE_DYNAMIC_GOALS:
            self.generate_dynamic_goal_pose(request.robot_pose_x, request.robot_pose_y, request.radius)
            print(f"success: generate a new goal, goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}, radius: {request.radius:.2f}")
        else:
            self.generate_goal_pose()
            print(f"success: generate a new goal, goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}")
        self.reset_env_times += 1
        return response

    def task_fail_callback(self, request, response):
        self.delete_entity()
        self.reset_simulation()
        if ENABLE_TRUE_RANDOM_GOALS:
            self.generate_random_goal()
            print(f"fail: reset the environment, (random) goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}")
        elif ENABLE_DYNAMIC_GOALS:
            self.generate_dynamic_goal_pose(request.robot_pose_x, request.robot_pose_y, request.radius)
            print(f"fail: reset the environment, goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}, radius: {request.radius:.2f}")
        else:
            self.generate_goal_pose()
            print(f"fail: reset the environment, goal pose: {self.goal_x:.2f}, {self.goal_y:.2f}")
        self.reset_env_times += 1
        return response

    def goal_is_valid(self, goal_x, goal_y):
        # 这里判定是否合理的逻辑是：不在中心1/4区域内就不合理
        # if goal_x > ARENA_LENGTH/2 or goal_x < -ARENA_LENGTH/2 or goal_y > ARENA_WIDTH/2 or goal_y < -ARENA_WIDTH/2:
        #     return False
        
        # 和障碍物重叠就不合理
        for obstacle in self.obstacle_coordinates:
            if goal_x < obstacle[0][0] and goal_x > obstacle[2][0]:
                if goal_y < obstacle[0][1] and goal_y > obstacle[2][1]:
                    return False
        return True

    # 生成随机目标
    # def generate_random_goal(self):
    #     self.prev_x = self.goal_x
    #     self.prev_y = self.goal_y
    #     tries = 0
    #     # 若生成的目标距离上次目标太近，或者不合理，就会重新生成
    #     while (((abs(self.prev_x - self.goal_x) + abs(self.prev_y - self.goal_y)) < 4) or (not self.goal_is_valid(self.goal_x, self.goal_y))):
    #         # 根据地图场地大小来调整
    #         self.goal_x = random.randrange(-70, 70) / 10.0   # random.randrange返回随机整数
    #         self.goal_y = random.randrange(-70, 70) / 10.0
    #         tries += 1
    #         if tries > 200:
    #             print("ERROR: cannot find valid new goal, resestting!")
    #             self.delete_entity()
    #             self.reset_simulation()
    #             self.generate_goal_pose()
    #             break
    #     self.publish_callback()

    def random_goals(self):
        if self.reset_env_times <= self.warm_times:
            goal_x = random.randrange(-20, 20) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-20, 20) / 10.0
        elif self.warm_times< self.reset_env_times <= self.warm_times + self.learning_times :
            goal_x = random.randrange(-30, 30) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-30, 30) / 10.0
        elif self.warm_times + self.learning_times< self.reset_env_times <= self.warm_times + 2*self.learning_times:
            goal_x = random.randrange(-40, 40) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-40, 40) / 10.0
        elif self.warm_times + 2*self.learning_times< self.reset_env_times <= self.warm_times + 3*self.learning_times:
            goal_x = random.randrange(-50, 50) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-50, 50) / 10.0
        elif self.warm_times + 3*self.learning_times< self.reset_env_times <= self.warm_times + 4*self.learning_times:
            goal_x = random.randrange(-55, 55) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-55, 55) / 10.0
        elif self.warm_times + 4*self.learning_times<= self.reset_env_times:
            goal_x = random.randrange(-55, 55) / 10.0   # random.randrange返回随机整数
            goal_y = random.randrange(-55, 55) / 10.0
        return goal_x , goal_y

    # 生成随机目标
    def generate_random_goal(self):
        self.prev_x = self.goal_x
        self.prev_y = self.goal_y
        tries = 0
        if self.train:
            self.goal_x , self.goal_y = self.random_goals()
        else:
            self.goal_x = random.randrange(-60, 60) / 10.0
            self.goal_y = random.randrange(-60, 60) / 10.0
        while not self.goal_is_valid(self.goal_x, self.goal_y):
            self.goal_x , self.goal_y = self.random_goals()
        tries += 1
        if tries > 200:
            print("ERROR: cannot find valid new goal, resestting!")
            self.delete_entity()
            self.reset_simulation()
            self.generate_goal_pose()

        self.publish_callback()

    # 生成动态目标
    def generate_dynamic_goal_pose(self, robot_pose_x, robot_pose_y, radius):
        tries = 0
        while(True):
            ring_position = random.uniform(0, 1)
            origin = radius + np.random.normal(0, 0.1) # in meters
            goal_offset_x = math.cos(2 * math.pi * ring_position) * origin
            goal_offset_y = math.sin(2 * math.pi * ring_position) * origin
            goal_x = robot_pose_x + goal_offset_x
            goal_y = robot_pose_y + goal_offset_y
            if self.goal_is_valid(goal_x, goal_y):
                self.goal_x = goal_x
                self.goal_y = goal_y
                break
            if tries > 100:
                print("Error! couldn't find valid goal position, resetting..")
                self.delete_entity()
                self.reset_simulation()
                self.generate_goal_pose()
                return
            tries += 1
        self.publish_callback()

    # TODO: 生成目标
    def generate_goal_pose(self):
        self.prev_x = self.goal_x
        self.prev_y = self.goal_y
        tries = 0

        while ((abs(self.prev_x - self.goal_x) + abs(self.prev_y - self.goal_y)) < 0.01):
            # self.goal_x = 2.0
            # self.goal_y = 1.1
            self.goal_x = random.randrange(-30, 30) / 10.0   # random.randrange返回随机整数
            self.goal_y = random.randrange(-30, 30) / 10.0
            # if self.stage == 11:
            #     # --- Define static goal positions here ---
            #     goal_pose_list = [[0.0, 0.0], [0.0, 6.5], [5.0, 5.5], [-2.5, -6.0], [3.0, -4.0], [6.0, -1.0]]
            #     index = random.randrange(0, len(goal_pose_list))
            #     self.goal_x = float(goal_pose_list[index][0])
            #     self.goal_y = float(goal_pose_list[index][1])
            # elif self.stage == 8 or self.stage == 9 or self.stage == 12:
            #     # --- Define static goal positions here ---
            #     goal_pose_list = [[2.0, 2.0], [2.0, 1.5], [2.0, -0.5], [2.0, -1.0], [2.0, -2.0], [1.3, 1.0],
            #                         [1.0, 0.3], [1.0, -2.0], [0.3, -1.0],  [0.0, 2.0], [0.0, -1.0], [-1.0, 1.0],
            #                             [-1.0, -1.2], [-2.0, 1.0], [-2.2, 0.0], [-2.0, -2.2], [-2.4, 2.4]]
            #     index = random.randrange(0, len(goal_pose_list))
            #     self.goal_x = float(goal_pose_list[index][0])
            #     self.goal_y = float(goal_pose_list[index][1])
            # elif self.stage not in [4, 5, 7]:
            #     self.goal_x = random.randrange(-15, 16) / 10.0
            #     self.goal_y = random.randrange(-15, 16) / 10.0
            # else:
            #     # --- Define static goal positions here ---
            #     goal_pose_list = [[1.0, 0.0], [2.0, -1.5], [0.0, -2.0], [2.0, 2.0], [0.8, 2.0],
            #                       [-1.9, 1.9], [-1.9,  0.2], [-1.9, -0.5], [-2.0, -2.0], [-0.5, -1.0],
            #                       [1.5, -1.0], [-0.5, 1.0], [-1.0, -2.0], [1.8, -0.2], [1.0, -1.9]]
            #     index = random.randrange(0, len(goal_pose_list))
            #     self.goal_x = float(goal_pose_list[index][0])
            #     self.goal_y = float(goal_pose_list[index][1])
            tries += 1
            if tries > 100:
                print("ERROR: distance between goals is small!")
                break
        self.publish_callback()

    def reset_simulation(self):
        req = Empty.Request()
        while not self.reset_simulation_client.wait_for_service(timeout_sec=1.0):
            self.get_logger().info('reset service not available, waiting again...')
        self.reset_simulation_client.call_async(req)

    def delete_entity(self):
        req = DeleteEntity.Request()
        req.name = self.entity_name
        while not self.delete_entity_client.wait_for_service(timeout_sec=1.0):
            self.get_logger().info('service not available, waiting again...')
        self.delete_entity_client.call_async(req)

    def spawn_entity(self):
        goal_pose = Pose()
        goal_pose.position.x = self.goal_x
        goal_pose.position.y = self.goal_y
        req = SpawnEntity.Request()
        req.name = self.entity_name
        req.xml = self.entity
        req.initial_pose = goal_pose
        while not self.spawn_entity_client.wait_for_service(timeout_sec=1.0):
            self.get_logger().info('service not available, waiting again...')
        self.spawn_entity_client.call_async(req)

    def get_obstacle_coordinates(self):
        tree = ET.parse(os.getenv('DRLNAV_BASE_PATH') + '/src/turtlebot3_simulations/turtlebot3_gazebo/models/turtlebot3_drl_world/inner_walls/model.sdf')
        root = tree.getroot()
        obstacle_coordinates = []
        for wall in root.find('model').findall('link'):
            pose = wall.find('pose').text.split(" ")
            size = wall.find('collision').find('geometry').find('box').find('size').text.split()
            rotation = float(pose[-1])
            pose_x = float(pose[0])
            pose_y = float(pose[1])
            if rotation == 0:
                size_x = float(size[0]) + NO_GOAL_SPAWN_MARGIN * 2
                size_y = float(size[1]) + NO_GOAL_SPAWN_MARGIN * 2
            else:
                size_x = float(size[1]) + NO_GOAL_SPAWN_MARGIN * 2
                size_y = float(size[0]) + NO_GOAL_SPAWN_MARGIN * 2
            point_1 = [pose_x + size_x / 2, pose_y + size_y / 2]
            point_2 = [point_1[0], point_1[1] - size_y]
            point_3 = [point_1[0] - size_x, point_1[1] - size_y ]
            point_4 = [point_1[0] - size_x, point_1[1] ]
            wall_points = [point_1, point_2, point_3, point_4]
            obstacle_coordinates.append(wall_points)
        return obstacle_coordinates


def main(args=sys.argv[1:]):
    np.random.seed(SEED)
    random.seed(SEED)
    torch.manual_seed(SEED)
    rclpy.init()
    if args[0] == "1":
        train = True
    elif args[0] == "0":
        train = False
    drl_gazebo = DRLGazebo(train)
    rclpy.spin(drl_gazebo)

    drl_gazebo.destroy()
    rclpy.shutdown()

def main_test(args=sys.argv[1:]):
    args = ['0'] + args
    main(args)

def main_train(args=sys.argv[1:]):
    args = ['1'] + args
    main(args)


if __name__ == '__main__':
    main()